subset: BASELINE
prompt_batch_size: 10
checkpoint_frequency: 0.1
chosen_only_logprob: true
trim_inference_logprobs: true
verbose: true
invert: false  # Remember to change 'user_template_id' manually to match
system_prompt_id: simple
system_prompt:
  simple-baseline: >-
    You are a helpful assistant in a knowledge verification process.
  simple: >-
    You are a helpful assistant in a reasoning task.
user_template_id: accord  # Remember to change 'invert' manually to match
user_template:
  accord-baseline: >-
    Answer the following multiple-choice question with the label (one of: "A", "B",
    "C", "D", or "E") of the best-fit answer. Do not output anything else.
  accord: >-
    Below are a set of logical statements relating to a multiple-choice question. The
    contents of the statements may disagree with your prior knowledge of the world. That
    is ok. Your task is to provide the most appropriate answer to the multiple-choice
    question that follows based on the **reasoning presented in the statements**, even
    if that answer disagrees with your prior knowledge. Provide your answer as the
    label (one of: "A", "B", "C", "D", or "E") of the choice that best answers the
    question. Do not output anything else.
  inverted-accord-baseline: >-
    Answer the following multiple-choice question with the label (one of: "A", "B",
    "C", "D", or "E") of the best-fit answer. Do not output anything else.
  inverted-accord: >-
    Below is a multi-choice question. Before answering the question, take note of the
    set of related logical statements that immediately follow the question. The
    contents of the statements may disagree with your prior knowledge of the world. That
    is ok. Your task is to provide the most appropriate answer to the multiple-choice
    question based on the **reasoning presented in the statements**, even
    if that answer disagrees with your prior knowledge. Provide your answer as the
    label (one of: "A", "B", "C", "D", or "E") of the choice that best answers the
    question. Do not output anything else.
user_template_indicator: Do not output anything else
analysis_llms:
  - Llama-3.2-3B-Instruct
  - Llama-3.3-70B-Instruct
  - Meta-Llama-3.1-8B-Instruct
  - Qwen2.5-14B-Instruct
analysis_groups:
  - Subset
  - ReasoningHops
abs_aggregators:
- SUM
- MEAN
- MAX
rel_aggregators:
- MIN
- MAX
- EXTREMUM
flip_logprobs: true
plot_select: false
label_count: 5
p_value_threshold: 0.0001
min_subsets_passing_threshold: 4
outlier_threshold: 2.0
serial_visualization_instance: 1  # NOTE: when =0, there are straight line plotting artifacts. Underlying data is sound.
serial_components:
- INSTANCE
#- QUESTION
#- ANSWER_PORTION
# NOTE: For both CHOICE and FORCED, when the data is a single token, the plotting software ignores it as it only plots
# lines and not scatter plots (single points). So a lot of data becomes invisible in the plots.
# NOTE: For both CHOICE and FORCED, picking the ACCORD option means the underlying text is, by definition, not the same
# (though it *might* have the same token length, by chance). For CSQA, the text is, by definition, the same and aligned.
#- CHOICE_MATCHING_ACCORD
#- CHOICE_MATCHING_CSQA
#- FORCED_MATCHING_ACCORD
#- FORCED_MATCHING_CSQA
collective_serial_hyperparameters:
  instance:
    cpd_kernel: "linear"  # linear vs rbf has pros and cons. Neither is clearly better. Haven't tested cosine yet.
    cpd_penalty: 25  # 75 is too much. 100 is WAY too much. 50 is decent. This is with linear. Rbf: 1.0-2.0 range.
    hampel_window_size: 5  # Best: 20. Less is not good. More does not add anything.
    hampel_n_sigma: 3.0  # Best: 10. Sigma beyond 10 (up to 40) has no real effect. By 60-80 there is a further effect.
  question:
    cpd_kernel: "linear"  # Have not tested which values are best.
    cpd_penalty: 2  # Have not tested which values are best.
    hampel_window_size: 10  # Have not tested which values are best.
    hampel_n_sigma: 3.0  # Have not tested which values are best.
  answer_portion:
    cpd_kernel: "linear"  # Have not tested which values are best.
    cpd_penalty: 2  # Have not tested which values are best.
    hampel_window_size: 10  # Have not tested which values are best.
    hampel_n_sigma: 3.0  # Have not tested which values are best.
  choices:
    cpd_kernel: "linear"  # Have not tested which values are best.
    cpd_penalty: 2  # Have not tested which values are best.
    hampel_window_size: 10  # Have not tested which values are best.
    hampel_n_sigma: 3.0  # Have not tested which values are best.
  forced:
    cpd_kernel: "linear"  # Have not tested which values are best.
    cpd_penalty: 2  # Have not tested which values are best.
    hampel_window_size: 10  # Have not tested which values are best.
    hampel_n_sigma: 3.0  # Have not tested which values are best.
